{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/data_for_train_test.csv')"
      ],
      "metadata": {
        "id": "qZ8qTEBdxS67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "TkMOluYZPPd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ar34u0Mvk2q",
        "outputId": "7036992d-5d09-4833-c9c3-b0329f1b38f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Bắt đầu quy trình train trên cpu ---\n",
            "--- [AUGMENTATION] Tạo 500 mẫu dữ liệu tiêu cực giả lập ---\n",
            "Đã load Item Embeddings: torch.Size([411, 8])\n",
            "Epoch 01 | Loss Total: 2.8334 (MSE: 2.6409, Rank: 0.3850) | Test RMSE: 0.9660\n",
            "Epoch 02 | Loss Total: 2.1283 (MSE: 1.9403, Rank: 0.3760) | Test RMSE: 1.0636\n",
            "Epoch 03 | Loss Total: 1.8127 (MSE: 1.6245, Rank: 0.3762) | Test RMSE: 1.0684\n",
            "Epoch 04 | Loss Total: 1.6549 (MSE: 1.4709, Rank: 0.3681) | Test RMSE: 1.0329\n",
            "Epoch 05 | Loss Total: 1.4237 (MSE: 1.2362, Rank: 0.3751) | Test RMSE: 1.0085\n",
            "Epoch 06 | Loss Total: 1.2229 (MSE: 1.0338, Rank: 0.3783) | Test RMSE: 0.9446\n",
            "Epoch 07 | Loss Total: 1.0465 (MSE: 0.8558, Rank: 0.3813) | Test RMSE: 0.9426\n",
            "Epoch 08 | Loss Total: 0.9467 (MSE: 0.7489, Rank: 0.3956) | Test RMSE: 0.9188\n",
            "Epoch 09 | Loss Total: 0.8864 (MSE: 0.6982, Rank: 0.3765) | Test RMSE: 0.8828\n",
            "Epoch 10 | Loss Total: 0.8438 (MSE: 0.6533, Rank: 0.3811) | Test RMSE: 0.8780\n",
            "Epoch 11 | Loss Total: 0.8008 (MSE: 0.6141, Rank: 0.3733) | Test RMSE: 0.8717\n",
            "Epoch 12 | Loss Total: 0.7889 (MSE: 0.6050, Rank: 0.3677) | Test RMSE: 0.8444\n",
            "Epoch 13 | Loss Total: 0.7701 (MSE: 0.5861, Rank: 0.3680) | Test RMSE: 0.8406\n",
            "Epoch 14 | Loss Total: 0.7827 (MSE: 0.5960, Rank: 0.3734) | Test RMSE: 0.8391\n",
            "Epoch 15 | Loss Total: 0.7476 (MSE: 0.5628, Rank: 0.3696) | Test RMSE: 0.8219\n",
            "Epoch 16 | Loss Total: 0.7410 (MSE: 0.5536, Rank: 0.3748) | Test RMSE: 0.8187\n",
            "Epoch 17 | Loss Total: 0.7227 (MSE: 0.5394, Rank: 0.3667) | Test RMSE: 0.8223\n",
            "Epoch 18 | Loss Total: 0.7436 (MSE: 0.5580, Rank: 0.3712) | Test RMSE: 0.8062\n",
            "Epoch 19 | Loss Total: 0.7137 (MSE: 0.5314, Rank: 0.3646) | Test RMSE: 0.8107\n",
            "Epoch 20 | Loss Total: 0.7038 (MSE: 0.5232, Rank: 0.3612) | Test RMSE: 0.8054\n",
            "\n",
            "Training xong! Best RMSE: 0.8054\n",
            "Model đã lưu tại: 'best_hybrid_model.pth'\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# 1. CẤU HÌNH\n",
        "\n",
        "CONFIG = {\n",
        "    'csv_path': 'data_for_train_test.csv',\n",
        "    'pt_path': 'nfm_rec_data.pt',\n",
        "    'batch_size': 32,\n",
        "    'lr': 0.002,\n",
        "    'epochs': 20,\n",
        "    'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
        "    'aug_samples': 500,\n",
        "    'ranking_weight': 0.5,\n",
        "    'margin': 0.5\n",
        "}\n",
        "\n",
        "def generate_synthetic_negative_data(original_df, num_fake_samples=500):\n",
        "    \"\"\"Tạo dữ liệu giả: Aspect thấp -> Rating thấp để model học chê\"\"\"\n",
        "    print(f\"--- [AUGMENTATION] Tạo {num_fake_samples} mẫu dữ liệu tiêu cực giả lập ---\")\n",
        "    existing_items = original_df['item_id'].unique()\n",
        "    fake_data = []\n",
        "\n",
        "    for _ in range(num_fake_samples):\n",
        "        rand_item = np.random.choice(existing_items)\n",
        "        bad_aspects = np.random.choice([1, 2], size=4, p=[0.8, 0.2])\n",
        "        bad_rating = np.random.uniform(0.5, 1.5)   # Rating thấp\n",
        "\n",
        "        row = {\n",
        "            'item_id': rand_item,\n",
        "            'ratings': bad_rating,\n",
        "            'Khong_Gian_Canh_Quan': bad_aspects[0], 'Ha_Tang_Tien_Ich': bad_aspects[1],\n",
        "            'Dich_Vu_Con_Nguoi': bad_aspects[2], 'Gia_Ca_Chi_Phi': bad_aspects[3],\n",
        "            'test': 0\n",
        "        }\n",
        "        fake_data.append(row)\n",
        "    return pd.concat([original_df, pd.DataFrame(fake_data)], ignore_index=True)\n",
        "\n",
        "\n",
        "# 2. DATASET\n",
        "\n",
        "class HybridDataset(Dataset):\n",
        "    def __init__(self, dataframe, all_item_ids, is_train=True):\n",
        "        self.df = dataframe\n",
        "        self.all_items = all_item_ids\n",
        "        self.is_train = is_train\n",
        "\n",
        "        self.aspect_cols = ['Khong_Gian_Canh_Quan', 'Ha_Tang_Tien_Ich', 'Dich_Vu_Con_Nguoi', 'Gia_Ca_Chi_Phi']\n",
        "\n",
        "        self.item_ids = torch.tensor(self.df['item_id'].values, dtype=torch.long)\n",
        "        self.ratings = torch.tensor(self.df['ratings'].values, dtype=torch.float32)\n",
        "\n",
        "        # Normalize Aspect\n",
        "        aspect_values = self.df[self.aspect_cols].fillna(0).values.astype(np.float32)\n",
        "        self.aspect_vecs = torch.tensor(aspect_values / 3.0, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # 1. Lấy mẫu Positive\n",
        "        pos_item = self.item_ids[idx]\n",
        "        aspect = self.aspect_vecs[idx]\n",
        "        rating = self.ratings[idx]\n",
        "\n",
        "        if not self.is_train:\n",
        "            # Nếu là test thì không cần negative\n",
        "            return pos_item, aspect, rating, pos_item\n",
        "\n",
        "        # 2. Lấy mẫu Negative (Random Item) cho bài toán Ranking\n",
        "        neg_item_val = np.random.choice(self.all_items)\n",
        "        while neg_item_val == pos_item.item():\n",
        "            neg_item_val = np.random.choice(self.all_items)\n",
        "\n",
        "        neg_item = torch.tensor(neg_item_val, dtype=torch.long)\n",
        "\n",
        "        return pos_item, aspect, rating, neg_item\n",
        "\n",
        "\n",
        "# 3. MODEL\n",
        "\n",
        "class ItemAspectRatingModel(nn.Module):\n",
        "    def __init__(self, pretrained_item_vecs, aspect_dim=4, hidden_layers=[64, 32], item_dropout_prob=0.3):\n",
        "        super(ItemAspectRatingModel, self).__init__()\n",
        "\n",
        "        self.item_embedding = nn.Embedding.from_pretrained(pretrained_item_vecs, freeze=False)\n",
        "        item_emb_dim = pretrained_item_vecs.shape[1]\n",
        "        self.item_dropout_prob = item_dropout_prob\n",
        "\n",
        "        # MLP\n",
        "        layers = []\n",
        "        in_dim = item_emb_dim + aspect_dim\n",
        "        for hidden_dim in hidden_layers:\n",
        "            layers.append(nn.Linear(in_dim, hidden_dim))\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(0.2))\n",
        "            in_dim = hidden_dim\n",
        "\n",
        "        self.mlp = nn.Sequential(*layers)\n",
        "        self.output_layer = nn.Linear(in_dim, 1)\n",
        "\n",
        "    def forward(self, item_idx, aspect_vec):\n",
        "        i_vec = self.item_embedding(item_idx)\n",
        "\n",
        "        # Item Dropout\n",
        "        if self.training and self.item_dropout_prob > 0:\n",
        "            mask = torch.bernoulli(torch.full((i_vec.shape[0], 1), 1 - self.item_dropout_prob)).to(i_vec.device)\n",
        "            i_vec = i_vec * mask\n",
        "\n",
        "        combined = torch.cat([i_vec, aspect_vec], dim=1)\n",
        "        return torch.sigmoid(self.output_layer(self.mlp(combined))) * 5.0\n",
        "\n",
        "\n",
        "# 4. TRAINING LOOP\n",
        "\n",
        "def train_hybrid_model():\n",
        "    print(f\"--- Bắt đầu quy trình train trên {CONFIG['device']} ---\")\n",
        "\n",
        "    # 1. Load Data\n",
        "    df_raw = pd.read_csv(CONFIG['csv_path'])\n",
        "    all_items = df_raw['item_id'].unique()\n",
        "\n",
        "    # Augmentation\n",
        "    df_full = generate_synthetic_negative_data(df_raw, num_fake_samples=CONFIG['aug_samples'])\n",
        "\n",
        "    # Split Train/Test\n",
        "    train_df = df_full[df_full['test'] == 0].reset_index(drop=True)\n",
        "    test_df = df_full[df_full['test'] == 1].reset_index(drop=True)\n",
        "\n",
        "    train_dataset = HybridDataset(train_df, all_items, is_train=True)\n",
        "    test_dataset = HybridDataset(test_df, all_items, is_train=False)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=CONFIG['batch_size'], shuffle=False)\n",
        "\n",
        "    # 2. Load Vector\n",
        "    try:\n",
        "        pt_data = torch.load(CONFIG['pt_path'])\n",
        "        item_vecs = pt_data['item_emb']\n",
        "        print(f\"Đã load Item Embeddings: {item_vecs.shape}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Lỗi load file PT: {e}\")\n",
        "        return\n",
        "\n",
        "    # 3. Model & Optimizer\n",
        "    model = ItemAspectRatingModel(pretrained_item_vecs=item_vecs, item_dropout_prob=0.3).to(CONFIG['device'])\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=CONFIG['lr'])\n",
        "\n",
        "    criterion_mse = nn.MSELoss()\n",
        "    criterion_rank = nn.MarginRankingLoss(margin=CONFIG['margin'])\n",
        "\n",
        "    # 4. Loop\n",
        "    best_rmse = float('inf')\n",
        "\n",
        "    for epoch in range(CONFIG['epochs']):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        mse_part = 0\n",
        "        rank_part = 0\n",
        "\n",
        "        for pos_item, aspect, rating, neg_item in train_loader:\n",
        "            pos_item, aspect = pos_item.to(CONFIG['device']), aspect.to(CONFIG['device'])\n",
        "            rating = rating.to(CONFIG['device'])\n",
        "            neg_item = neg_item.to(CONFIG['device'])\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # --- Forward Pass ---\n",
        "            pred_pos = model(pos_item, aspect).squeeze()\n",
        "            pred_neg = model(neg_item, aspect).squeeze()\n",
        "\n",
        "            # --- Tính Loss ---\n",
        "            loss_mse = criterion_mse(pred_pos, rating)\n",
        "\n",
        "            # 2. Ranking Loss\n",
        "            high_rating_mask = (rating >= 4.0).float()\n",
        "\n",
        "            target = torch.ones_like(pred_pos)\n",
        "\n",
        "            rank_loss_raw = torch.clamp(CONFIG['margin'] - (pred_pos - pred_neg), min=0)\n",
        "            loss_rank = (rank_loss_raw * high_rating_mask).mean()\n",
        "\n",
        "            # 3. Tổng hợp Loss\n",
        "            loss_total = loss_mse + CONFIG['ranking_weight'] * loss_rank\n",
        "\n",
        "            loss_total.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss_total.item()\n",
        "            mse_part += loss_mse.item()\n",
        "            rank_part += loss_rank.item()\n",
        "\n",
        "        # --- Eval ---\n",
        "        model.eval()\n",
        "        total_test_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for pos_item, aspect, rating, _ in test_loader:\n",
        "                pos_item, aspect, rating = pos_item.to(CONFIG['device']), aspect.to(CONFIG['device']), rating.to(CONFIG['device'])\n",
        "                pred = model(pos_item, aspect).squeeze()\n",
        "                total_test_loss += criterion_mse(pred, rating).item()\n",
        "\n",
        "        rmse = np.sqrt(total_test_loss / len(test_loader))\n",
        "\n",
        "        print(f\"Epoch {epoch+1:02d} | Loss Total: {total_loss/len(train_loader):.4f} \"\n",
        "              f\"(MSE: {mse_part/len(train_loader):.4f}, Rank: {rank_part/len(train_loader):.4f}) \"\n",
        "              f\"| Test RMSE: {rmse:.4f}\")\n",
        "\n",
        "        if rmse < best_rmse:\n",
        "            best_rmse = rmse\n",
        "            torch.save(model.state_dict(), 'best_hybrid_model.pth')\n",
        "\n",
        "    print(f\"\\nTraining xong! Best RMSE: {best_rmse:.4f}\")\n",
        "    print(\"Model đã lưu tại: 'best_hybrid_model.pth'\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train_hybrid_model()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ItemAspectRatingModel(nn.Module):\n",
        "    def __init__(self, pretrained_item_vecs, aspect_dim=4, hidden_layers=[64, 32], item_dropout_prob=0.3):\n",
        "        super(ItemAspectRatingModel, self).__init__()\n",
        "\n",
        "        self.item_embedding = nn.Embedding.from_pretrained(pretrained_item_vecs, freeze=False)\n",
        "        item_emb_dim = pretrained_item_vecs.shape[1]\n",
        "        self.item_dropout_prob = item_dropout_prob\n",
        "\n",
        "        # MLP\n",
        "        layers = []\n",
        "        in_dim = item_emb_dim + aspect_dim\n",
        "        for hidden_dim in hidden_layers:\n",
        "            layers.append(nn.Linear(in_dim, hidden_dim))\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(0.2))\n",
        "            in_dim = hidden_dim\n",
        "\n",
        "        self.mlp = nn.Sequential(*layers)\n",
        "        self.output_layer = nn.Linear(in_dim, 1)\n",
        "\n",
        "    def forward(self, item_idx, aspect_vec):\n",
        "        i_vec = self.item_embedding(item_idx)\n",
        "\n",
        "        # Item Dropout\n",
        "        if self.training and self.item_dropout_prob > 0:\n",
        "            mask = torch.bernoulli(torch.full((i_vec.shape[0], 1), 1 - self.item_dropout_prob)).to(i_vec.device)\n",
        "            i_vec = i_vec * mask\n",
        "\n",
        "        combined = torch.cat([i_vec, aspect_vec], dim=1)\n",
        "        return torch.sigmoid(self.output_layer(self.mlp(combined))) * 5.0"
      ],
      "metadata": {
        "id": "lcYNgsNFPXXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "def load_model_inference(model_path, pt_file_path):\n",
        "    \"\"\"\n",
        "    Load model lên để dự đoán (Inference).\n",
        "    Cần file .pt gốc để lấy lại Shape của Item Embedding.\n",
        "    \"\"\"\n",
        "    # 1. Load Config\n",
        "    config_path = model_path.replace('.pth', '_config.json')\n",
        "    if not os.path.exists(config_path):\n",
        "        print(\"⚠️ Không tìm thấy file config, sẽ dùng config mặc định.\")\n",
        "        config = {'hidden_layers': [64, 32], 'aspect_dim': 4}\n",
        "    else:\n",
        "        with open(config_path, 'r') as f:\n",
        "            config = json.load(f)\n",
        "\n",
        "    # 2. Load Vector Gốc\n",
        "    try:\n",
        "        pt_data = torch.load(pt_file_path)\n",
        "        item_vecs = pt_data['item_emb']\n",
        "    except Exception as e:\n",
        "        raise FileNotFoundError(f\"❌ Cần file {pt_file_path} để khởi tạo model! Lỗi: {e}\")\n",
        "\n",
        "    # 3. Khởi tạo kiến trúc Model\n",
        "    model = ItemAspectRatingModel(\n",
        "        pretrained_item_vecs=item_vecs,\n",
        "        aspect_dim=config.get('aspect_dim', 4),\n",
        "        hidden_layers=config.get('hidden_layers', [64, 32]),\n",
        "        item_dropout_prob=0\n",
        "    )\n",
        "\n",
        "    # 4. Load Trọng số đã train\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    print(\"✅ Load model thành công! Sẵn sàng dự đoán.\")\n",
        "    return model, device"
      ],
      "metadata": {
        "id": "vvoV3fvCvt63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model_inference('/content/best_hybrid_model.pth', '/content/nfm_rec_data.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2G4DrTRxvwYh",
        "outputId": "4df49674-67cd-44f8-9ded-d79c6254b7c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ Không tìm thấy file config, sẽ dùng config mặc định.\n",
            "✅ Load model thành công! Sẵn sàng dự đoán.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# DEMO DỰ ĐOÁN\n",
        "\n",
        "model_path = 'best_hybrid_model.pth'\n",
        "pt_path = 'nfm_rec_data.pt'\n",
        "\n",
        "try:\n",
        "    model, device = load_model_inference(model_path, pt_path)\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "    exit()\n",
        "\n",
        "# 2. Hàm dự đoán rating\n",
        "def predict_single_case(model, item_id, aspects):\n",
        "    item_tensor = torch.tensor([item_id], dtype=torch.long).to(device)\n",
        "\n",
        "    aspect_tensor = torch.tensor([aspects], dtype=torch.float32).to(device) / 3.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        prediction = model(item_tensor, aspect_tensor)\n",
        "\n",
        "    return prediction.item()\n",
        "\n",
        "# 3. Test thử các trường hợp\n",
        "print(\"\\n--- KẾT QUẢ DỰ ĐOÁN ---\")\n",
        "\n",
        "item_id = 121\n",
        "good_aspects = [3, 3, 3, 3]\n",
        "rating = predict_single_case(model, item_id, good_aspects)\n",
        "print(f\"Item {item_id} | Review Tốt {good_aspects} -> Rating: {rating:.2f}/5.0\")\n",
        "\n",
        "bad_aspects = [0, 0, 0, 1]\n",
        "rating_bad = predict_single_case(model, item_id, bad_aspects)\n",
        "print(f\"Item {item_id} | Review Tệ  {bad_aspects} -> Rating: {rating_bad:.2f}/5.0\")\n",
        "\n",
        "item_id_2 = 10\n",
        "rating_2 = predict_single_case(model, item_id_2, [2, 2, 2, 2])\n",
        "print(f\"Item {item_id_2}  | Review Vừa {good_aspects} -> Rating: {rating_2:.2f}/5.0\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jK-Cfd0RvxwF",
        "outputId": "532485f3-1803-4fc2-83fb-1d24a5c12990"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ Không tìm thấy file config, sẽ dùng config mặc định.\n",
            "✅ Load model thành công! Sẵn sàng dự đoán.\n",
            "\n",
            "--- KẾT QUẢ DỰ ĐOÁN ---\n",
            "Item 121 | Review Tốt [3, 3, 3, 3] -> Rating: 4.28/5.0\n",
            "Item 121 | Review Tệ  [0, 0, 0, 1] -> Rating: 3.12/5.0\n",
            "Item 10  | Review Vừa [3, 3, 3, 3] -> Rating: 2.48/5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ranking(df, user_id,topk = 10):\n",
        "  temp = df[df['user_id'] == user_id]\n",
        "  temp = temp.sample(n=1)\n",
        "  temp_vec = temp[['Khong_Gian_Canh_Quan',\t'Ha_Tang_Tien_Ich',\t'Dich_Vu_Con_Nguoi',\t'Gia_Ca_Chi_Phi']].values.tolist()\n",
        "  temp_vec = temp_vec[0]\n",
        "  ratings = []\n",
        "  for j in df['item_id'].unique():\n",
        "    ratings.append((j,predict_single_case(model, j, temp_vec)))\n",
        "\n",
        "  result = sorted(ratings, key=lambda x: x[1], reverse=True)[:topk]\n",
        "  return result"
      ],
      "metadata": {
        "id": "MtwU2UsNvzMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ranking(df, 10)"
      ],
      "metadata": {
        "id": "jZy4-IP9Paen",
        "outputId": "17cebe1d-b21c-44b2-a1e1-60f8675287ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(np.int64(240), 4.954970359802246),\n",
              " (np.int64(8), 4.9522247314453125),\n",
              " (np.int64(117), 4.951949119567871),\n",
              " (np.int64(380), 4.950490474700928),\n",
              " (np.int64(237), 4.94845724105835),\n",
              " (np.int64(398), 4.9460129737854),\n",
              " (np.int64(234), 4.945907115936279),\n",
              " (np.int64(388), 4.943285942077637),\n",
              " (np.int64(162), 4.936796188354492),\n",
              " (np.int64(251), 4.936674118041992)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total = 0\n",
        "test = df[df['test'] == 1]\n",
        "for i in test['user_id'].unique():\n",
        "  iid = test[test['user_id'] == i]['item_id'].iloc[0]\n",
        "  exist = any(item_id == iid for item_id,rank in ranking(test,i,10))\n",
        "  if exist:\n",
        "    total += 1\n",
        "print(total/len(test['user_id'].unique()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MC55Bh_v0Z3",
        "outputId": "12188f50-26be-42a4-dc90-fa3cd5df7e90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.03015873015873016\n"
          ]
        }
      ]
    }
  ]
}